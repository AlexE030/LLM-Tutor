services:
  llama_api:
    build:
      context: models/llama-2-7b
    container_name: llama_api
    runtime: nvidia
    ports:
      - "8001:8000"
    networks:
      - llm-network
    environment:
      HF_TOKEN: ${HF_TOKEN}
      NVIDIA_VISIBLE_DEVICES: 0
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
      LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda/lib64
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['1']
              capabilities: [ gpu ]
    command: [ "uvicorn", "agent_llama:app", "--host", "0.0.0.0", "--port", "8000" ]

  zephyr_api:
    build:
      context: models/zephyr-7b
    container_name: zephyr_api
    ports:
      - "8002:8000"
    networks:
      - llm-network
    environment:
      HF_TOKEN: ${HF_TOKEN}
    restart: always
    command: [ "uvicorn", "agent_zephyr:app", "--host", "0.0.0.0", "--port", "8000" ]

  mistral_api:
    build:
      context: models/mistral-7b
    container_name: mistral_api
    ports:
      - "8003:8000"
    networks:
      - llm-network
    environment:
      HF_TOKEN: ${HF_TOKEN}
    restart: always
    command: [ "uvicorn", "agent_mistral:app", "--host", "0.0.0.0", "--port", "8000" ]

  bloom_api:
    build:
      context: models/bloom
    container_name: bloom_api
    runtime: nvidia
    ports:
      - "8004:8000"
    networks:
      - llm-network
    environment:
      NVIDIA_VISIBLE_DEVICES: 1
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
      LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda/lib64
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['1']
              capabilities: [ gpu ]
    command: [ "uvicorn", "agent_bloom:app", "--host", "0.0.0.0", "--port", "8000" ]

  router_api:
    build:
      context: ./router
    container_name: router_api
    depends_on:
      - llama_api
      - zephyr_api
      - mistral_api
      - bloom_api
    ports:
      - "8080:8000"
    networks:
      - llm-network
    restart: always
    command: ["uvicorn", "router:app", "--host", "0.0.0.0", "--port", "8000"]

networks:
  llm-network:
    name: llm-network
    driver: bridge
